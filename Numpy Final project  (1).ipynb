{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97c7fbbc",
   "metadata": {},
   "source": [
    "\n",
    "looking at a Loan Data from a European Central Bank. Our job as Data Analysts is to make the dataset ready, that is Gather,clean and preprocess it and pass it to the Data Scientists who would build a Credit Risk Model.\n",
    "\n",
    "We will of course note down all the changes we are making to the dataset in a documentation file - which would be invaluable to the Data Scientists or whoever would be working with the dataset after us.  \n",
    "\n",
    "Our major role in the dataset would be to examine the data, import the data, split the data.\n",
    "\n",
    "### Project:\n",
    "\n",
    "You are working as  Data Analyst in a Data Science Team of a Central Bank in Europe. Your Team has been tasked to create a `Credit Risk Model(CRM)` which estimates the probability of default for every personal account.  Therefore the following terms would be evaluated on the dataset, `Probability of default, Recovery rate, Credit Risk Modelling`. They have asked us to take the datasets and prepare it for the models they intend to run. They have provided details on the columns in the dataset, and a set of rules we should follow during preprocessing. Infact, the data cleaning and preprocessing task, represent the essence of the data cleaning job. Here are some guided steps:\n",
    "\n",
    "- The Loan data is a sample from a larger dataset that belongs to an afiliate bank based in the united states. Therefore, the default currenccy is in dollars  so we need to provide their Euro Equivalents.\n",
    "- Every categorical variable must be quantified. That is, we need to change any text column into numbers.\n",
    "- For the Issue date, we can split them into months. For others, we only care if they provide a positive or negative connotations. So we would be turning them into dummy variables that holds either 0 or 1.\n",
    "\n",
    "Finally, When measuring credit worthiness, we need to be extremely risk-averse and distrustful of any unavailable data. Thats why the consensus in the field is that missing information suggests foul play  because loan applications are self reporting. To elaborate, since candidates fill their loan applications manually, there is an incentive to withold information which can lower their chances to get a loan. Therefore, if the information isn't availble, we would just assume the worst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ea14d6",
   "metadata": {},
   "source": [
    "### Import the Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "644070fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy and standardize in case of scientific notations\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True, linewidth=100, precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3bd87b",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a82949e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,         nan,    35000.  , ...,         nan,         nan,     9452.96],\n",
       "       [57693261.  ,         nan,    30000.  , ...,         nan,         nan,     4679.7 ],\n",
       "       [59432726.  ,         nan,    15000.  , ...,         nan,         nan,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,         nan,    10000.  , ...,         nan,         nan,     2185.64],\n",
       "       [46154151.  ,         nan,         nan, ...,         nan,         nan,     3199.4 ],\n",
       "       [66055249.  ,         nan,    10000.  , ...,         nan,         nan,      301.9 ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_np=np.genfromtxt(\"C:\\\\Users\\\\USER\\\\Downloads\\\\loan-data.csv\",\n",
    "                          delimiter=',',\n",
    "                         skip_header=1,\n",
    "                          autostrip=True)\n",
    "                       \n",
    "                        \n",
    "raw_data_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990427c0",
   "metadata": {},
   "source": [
    "### Checking for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7210aa6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88005"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for the count of missing data\n",
    "np.isnan(raw_data_np).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5354fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_340\\3972857773.py:3: RuntimeWarning: Mean of empty slice\n",
      "  temprorary_mean=np.nanmean(raw_data_np,axis=0).round(2)\n"
     ]
    }
   ],
   "source": [
    "#lets create filler values for the dataset as well as a temporary mean.\n",
    "temporary_fill=np.nanmax(raw_data_np).round(2)+1\n",
    "temprorary_mean=np.nanmean(raw_data_np,axis=0).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411ed927",
   "metadata": {},
   "source": [
    "Warnings do not stop codes from running, they only tell us that we might be overlooking somethings.\n",
    "In this case, we might be having columns with only nan values in these cases we wont have a  mean for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd7e1f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([54015809.19,         nan,    15273.46,         nan,    15311.04,         nan,       16.62,\n",
       "            440.92,         nan,         nan,         nan,         nan,         nan,     3143.85])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets check for how many columns with missing values.  #call temporary mean\n",
    "temprorary_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5be348",
   "metadata": {},
   "source": [
    "We have about 8  columns with missing data, or in this case text data. which are nans.\n",
    "\n",
    "We would need to get the mins and maxs from the dataset. The head of Data Analytics has given iuis casting directions on how to go about filling missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34de33a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_340\\3311710201.py:2: RuntimeWarning: All-NaN slice encountered\n",
      "  temporary_stats=np.array([np.nanmin(raw_data_np,axis=0),\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_340\\3311710201.py:3: RuntimeWarning: Mean of empty slice\n",
      "  np.nanmean(raw_data_np,axis=0),\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_340\\3311710201.py:4: RuntimeWarning: All-NaN slice encountered\n",
      "  np.nanmax(raw_data_np,axis=0)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  373332.  ,         nan,     1000.  ,         nan,     1000.  ,         nan,        6.  ,\n",
       "              31.42,         nan,         nan,         nan,         nan,         nan,        0.  ],\n",
       "       [54015809.19,         nan,    15273.46,         nan,    15311.04,         nan,       16.62,\n",
       "             440.92,         nan,         nan,         nan,         nan,         nan,     3143.85],\n",
       "       [68616519.  ,         nan,    35000.  ,         nan,    35000.  ,         nan,       28.99,\n",
       "            1372.97,         nan,         nan,         nan,         nan,         nan,    41913.62]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create an array temporary stats variable to store the the min, mean and max for every column in raw_data_np\n",
    "temporary_stats=np.array([np.nanmin(raw_data_np,axis=0),\n",
    "                         np.nanmean(raw_data_np,axis=0),\n",
    "                         np.nanmax(raw_data_np,axis=0)])\n",
    "temporary_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b7b873",
   "metadata": {},
   "source": [
    "### Splitting the Dataset\n",
    "\n",
    "We want to split the dataset into Text Data and Numeric Data.\n",
    "\n",
    "To split the dataset, we first need to know which type of data belongs to which"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f22fcf",
   "metadata": {},
   "source": [
    "######  splitting the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da84bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#string column. we can use the argwhere() to find the text columns.  make sure the ouput is a flattened 1d array\n",
    "column_strings=np.argwhere(np.isnan(temprorary_mean)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c9b7a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  5,  8,  9, 10, 11, 12], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5998f54",
   "metadata": {},
   "source": [
    "To better understand the above, the default for .argwhere() is to find values different from 0, therefore, .isnan() returns True for values that are nan in the temporary mean. since True is different from 0, .argwhere() would return the indices of those column different from 0 or in this case strings. This would make up our text columns. The squeeze function converts the 2d output to a 1d array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bf5382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#string numeric\n",
    "column_numeric=np.argwhere(np.isnan(temprorary_mean)==False).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "793253d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  4,  6,  7, 13], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8315e20c",
   "metadata": {},
   "source": [
    "### Reimporting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb26d70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['15-May', 'Current', '36 months', ..., 'Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226', 'CA'],\n",
       "       ['', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261', 'NY'],\n",
       "       ['15-Sep', 'Current', '36 months', ..., 'Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726', 'PA'],\n",
       "       ...,\n",
       "       ['15-Jun', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990', 'CA'],\n",
       "       ['15-Apr', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151', 'OH'],\n",
       "       ['15-Dec', 'Current', '36 months', ..., '',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249', 'IL']],\n",
       "      dtype='<U69')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#string import\n",
    "loan_data_strings=np.genfromtxt(\"C:\\\\Users\\\\USER\\\\Downloads\\\\loan-data.csv\",\n",
    "                        delimiter=',',\n",
    "                        skip_header=1,\n",
    "                        autostrip=True,\n",
    "                        usecols=column_strings,\n",
    "                        dtype=str)\n",
    "                        \n",
    "loan_data_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df49a50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    35000.  ,       13.33,     1184.86,     9452.96],\n",
       "       [57693261.  ,    30000.  ,    30000.  , 68616520.  ,      938.57,     4679.7 ],\n",
       "       [59432726.  ,    15000.  ,    15000.  , 68616520.  ,      494.86,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,    10000.  , 68616520.  , 68616520.  ,     2185.64],\n",
       "       [46154151.  , 68616520.  ,    10000.  ,       16.55,      354.3 ,     3199.4 ],\n",
       "       [66055249.  ,    10000.  ,    10000.  , 68616520.  ,      309.97,      301.9 ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#numeric import\n",
    "loan_data_numeric=np.genfromtxt(\"C:\\\\Users\\\\USER\\\\Downloads\\\\loan-data.csv\",\n",
    "                        delimiter=',',\n",
    "                        skip_header=1,\n",
    "                        autostrip=True,\n",
    "                        usecols=column_numeric,\n",
    "                        filling_values=temporary_fill)\n",
    "                        \n",
    "loan_data_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4641c38",
   "metadata": {},
   "source": [
    "### The names of the columns\n",
    "\n",
    "We dont want to loose track of the columns we have so it is imperative we get the names of the columns we would be working on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a514e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'issue_d', 'loan_amnt', 'loan_status', 'funded_amnt', 'term', 'int_rate',\n",
       "       'installment', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state',\n",
       "       'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets get the full header of the dataset\n",
    "header_full=np.genfromtxt(\"C:\\\\Users\\\\USER\\\\Downloads\\\\loan-data.csv\",\n",
    "                        delimiter=',',\n",
    "                        skip_footer=raw_data_np.shape[0],\n",
    "                        autostrip=True,\n",
    "                        dtype=str)\n",
    "                        \n",
    "header_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd07cfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create two header names for strings and numeric data\n",
    "header_strings,header_numeric=header_full[column_strings],header_full[column_numeric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ddb9d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_d', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call the header strings\n",
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3f39478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call header numeric\n",
    "header_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e140a7",
   "metadata": {},
   "source": [
    "### Creating checkpoints\n",
    "\n",
    "Checkpoints in Jupyter Notebook are created to save the state of the notebook at a particular point in time. This can be useful for a number of reasons, such as:\n",
    "\n",
    "- Recovering from crashes or errors: If your notebook crashes or you make an accidental change that you don't want, you can revert to a previous checkpoint.\n",
    "- Undoing changes: If you make a change to your notebook that you don't like, you can revert to a previous checkpoint to undo the change.\n",
    "- Comparing versions: If you're working on a long-running project, you can create checkpoints at different points in time to compare how your code has changed over time.\n",
    "- Debugging issues: If you encounter a bug in your notebook, you can use checkpoints to isolate the problem. By comparing the state of the notebook at different checkpoints, you can identify which code changes led to the bug."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc8fc60",
   "metadata": {},
   "source": [
    "### Manipulating String Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7621ed25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_d', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call the header strings\n",
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43f042e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the first item is issue_d we can rename it to issue date\n",
    "header_strings[0]=\"issue_date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71210819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['15-May', '', '15-Sep', ..., '15-Jun', '15-Apr', '15-Dec'], dtype='<U69')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets examine the data closelu and see what it looks like\n",
    "loan_data_strings[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa5902c",
   "metadata": {},
   "source": [
    "### Issue Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b86501dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the issue date column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a2338a",
   "metadata": {},
   "source": [
    "we can see the issue date contains the first three letters of the month and the year accompanying it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "801b6146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '15-Apr', '15-Aug', '15-Dec', '15-Feb', '15-Jan', '15-Jul', '15-Jun', '15-Mar',\n",
       "       '15-May', '15-Nov', '15-Oct', '15-Sep'], dtype='<U69')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call the unique vlues of the issue date column\n",
    "np.unique(loan_data_strings[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85ecdbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chararray(['May', '', 'Sep', ..., 'Jun', 'Apr', 'Dec'], dtype='<U69')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets strip the -15 part from the column since they are all from the year 2015. \n",
    "np.chararray.strip(loan_data_strings[:,0],\"15-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14a8451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets be sure the changes are permanent\n",
    "loan_data_strings[:,0]=np.chararray.strip(loan_data_strings[:,0],\"15-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d814350b",
   "metadata": {},
   "source": [
    "The output is better, howwver given that we are in Numpy, what we would usually need to do in our analysis, is to replace the months with integers. This approach will enable our data to take less memory as integers take less space than texts. Dont forget we have missing values as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c914512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to replace the months with numeric, we would first of all create an array with the months\n",
    "months=np.array([\"\",\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4de6346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use a for loop to iterate through the issue date column and change the months to integer values\n",
    "for i in range(13):\n",
    "    loan_data_strings[:,0]=np.where(loan_data_strings[:,0]==months[i],\n",
    "                                    i,\n",
    "                                    loan_data_strings[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1275b836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '10', '11', '12', '2', '3', '4', '5', '6', '7', '8', '9'], dtype='<U69')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call the unique vlues for the issue date\n",
    "np.unique(loan_data_strings[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0cfc80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace the missing months with 0\n",
    "loan_data_strings[:,0]=np.where(loan_data_strings[:,0]==\"\",\n",
    "                               0,\n",
    "                               loan_data_strings[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed7ad17",
   "metadata": {},
   "source": [
    "### Loan Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da7ccd9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call the header_strings\n",
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e03e3137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Current', 'Current', 'Current', ..., 'Current', 'Current', 'Current'], dtype='<U69')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call the loan status column on loan_data_strings\n",
    "loan_data_strings[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc6d6003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Charged Off', 'Current', 'Default', 'Fully Paid', 'In Grace Period', 'Issued',\n",
       "       'Late (16-30 days)', 'Late (31-120 days)'], dtype='<U69')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retrieve the unique values from this column\n",
    "np.unique(loan_data_strings[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d461859f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets get the number of unique values in the column\n",
    "np.unique(loan_data_strings[:,1]).size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6d286b",
   "metadata": {},
   "source": [
    "we would like to create dummy variables to replace each of the 9 individual elements, howwver we have been told regressions according to the probability of default, only cares if the candidate is in a stable financal condition or not. in otherwords, we are creating two groups to see if the loan condition is good or bad.\n",
    "\n",
    "To put into context,\n",
    "\n",
    "- Good: current,Fully paid, in Grace Period, Issued, Late(16-30 days)  - this is because they have defualted for less than a month and perhaps still waiting for their salaries before they could pay\n",
    "- Bad: charged off, Default, Late(31-120 days), since we assume the worse, those with missing status will be considered as bad loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f2cc1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to do this, we can create a variable to store either the good or the bad. Ensure to write them as they appear\n",
    "status_bad=np.array(['','Charged Off','Default','Late (31-120 days)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ccdf023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use a where function and isin to store the valiues as 0 and 1. status_bad=0, else 1\n",
    "loan_data_strings[:,1]=np.where(np.isin(loan_data_strings[:,1],status_bad),0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ca981c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['5', '1', '36 months', ..., 'Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226', 'CA'],\n",
       "       ['0', '1', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261', 'NY'],\n",
       "       ['9', '1', '36 months', ..., 'Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726', 'PA'],\n",
       "       ...,\n",
       "       ['6', '1', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990', 'CA'],\n",
       "       ['4', '1', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151', 'OH'],\n",
       "       ['12', '1', '36 months', ..., '',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249', 'IL']],\n",
       "      dtype='<U69')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315dacaa",
   "metadata": {},
   "source": [
    "### Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12e63649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url',\n",
       "       'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display the header_strings\n",
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "084597f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['36 months', '36 months', '36 months', ..., '36 months', '36 months', '36 months'],\n",
       "      dtype='<U69')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examine it by calling the column\n",
    "loan_data_strings[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16138aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '36 months', '60 months'], dtype='<U69')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call the unique values for the column\n",
    "np.unique(loan_data_strings[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "508f8a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '36', '60'], dtype='<U69')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#strip the months part from the values in the column\n",
    "loan_data_strings[:,2]=np.chararray.strip(loan_data_strings[:,2],\" months\")\n",
    "np.unique(loan_data_strings[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eff51900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'grade', 'sub_grade', 'verification_status',\n",
       "       'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets make sure the column name is properly written. let it be term_months\n",
    "header_strings[2]=\"term_months\"\n",
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f0c9d2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use a where function to replace all the missing values to 60 months since we are assuming the worse\n",
    "loan_data_strings[:,2]=np.where(loan_data_strings[:,2]==\"\",\n",
    "                               60,\n",
    "                               loan_data_strings[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023f8152",
   "metadata": {},
   "source": [
    "### Grade and Sub Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb94b546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'grade', 'sub_grade', 'verification_status',\n",
       "       'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display the header strings\n",
    "header_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d32a058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C', 'A', 'B', ..., 'A', 'D', 'A'], dtype='<U69')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examine the column on the loan_data\n",
    "loan_data_strings[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73c8fe93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='<U69')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for the distinct values  in thecolumn\n",
    "np.unique(loan_data_strings[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c3c98bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C3', 'A5', 'B5', ..., 'A5', 'D2', 'A4'], dtype='<U69')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#before we proceed further, lets examine the subgrade\n",
    "loan_data_strings[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db4477e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4',\n",
       "       'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4',\n",
       "       'F5', 'G1', 'G2', 'G3', 'G4', 'G5'], dtype='<U69')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for the distinct values  in the subgrade column\n",
    "np.unique(loan_data_strings[:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdf6e17",
   "metadata": {},
   "source": [
    "from what we can gather about the two columns, it means that for every element in the grade, there is an corresponding element in the  sub grade column numbered 1 to 5.\n",
    "This theoretically makes the grade column redundant, however, this might not be true as we can use the grade column to fill for missing values in the sub grade column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907da947",
   "metadata": {},
   "source": [
    "### Filling the Sub grade column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5ab54f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use a for loop to   fill missing valuues in the subgrade column row wise, based on the the values in the grade column\n",
    "for i in np.unique(loan_data_strings[:,3])[1]:\n",
    "    loan_data_strings[:,4]=np.where((loan_data_strings[:,4]==\"\")& (loan_data_strings[:,3]==i),\n",
    "                                                                   i+\"5\",\n",
    "                                                                   loan_data_strings[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ace64e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4',\n",
       "       'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4',\n",
       "       'F5', 'G1', 'G2', 'G3', 'G4', 'G5'], dtype='<U69')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for the distinct values  in the subgrade column again\n",
    "np.unique(loan_data_strings[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dd9f969c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['', 'A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4',\n",
       "        'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4',\n",
       "        'F5', 'G1', 'G2', 'G3', 'G4', 'G5'], dtype='<U69'),\n",
       " array([424, 285, 278, 239, 323, 592, 509, 517, 530, 553, 494, 629, 567, 586, 564, 423, 391, 267,\n",
       "        250, 255, 223, 235, 162, 171, 139, 114,  94,  52,  34,  43,  16,  19,  10,   3,   7,   2],\n",
       "       dtype=int64))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets check the number of times each values occur in the dataset\n",
    "np.unique(loan_data_strings[:,4],return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd52e8a",
   "metadata": {},
   "source": [
    "we see that the mising value occurs 9 times. Our dataset is 10000 rows. technically , we can afford to drop this columns and it wont hinder our analysis.\n",
    "9 out of 10000 is insignificant. However, as credit risk analysts, we can use something else to fill this since we want to make sure we account for those that have defaulted in their loan payments. we can introduce another subgrade H1 hich is lower than even G5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "49f3881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the missing elemnts in the subgrade with H1\n",
    "loan_data_strings[:,4]=np.where(loan_data_strings[:,4]==\"\",\n",
    "                                \"H1\",\n",
    "                               loan_data_strings[:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ff7775",
   "metadata": {},
   "source": [
    "### Deleting the grade Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "27b7e5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the np.delet to remove the grade column from the dataset\n",
    "loan_data_strings=np.delete(loan_data_strings,3,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cc8a98ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C3', 'A5', 'B5', ..., 'A5', 'D2', 'A4'], dtype='<U69')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  call the third column fro  the loan data strings\n",
    "loan_data_strings[:,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b100c117",
   "metadata": {},
   "source": [
    "We see that the third column is now sub grade rather than grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd9fa6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the grade column from the header_strings\n",
    "header_strings=np.delete(header_strings,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3b0cb698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sub_grade'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#when we display the 4th elemnt of the header, we see sub grade, rather than grade\n",
    "header_strings[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90819ae4",
   "metadata": {},
   "source": [
    "### Converting the subgrade Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "79b77ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to convert the suub_grade_column to numbers, we can use the where function or a dictionary.\n",
    "keys=list(np.unique(loan_data_strings[:,3]))\n",
    "\n",
    "values=list(range(1,37))\n",
    "dict_sub_grade=dict(zip(keys,values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7c1e3d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#althernative code to count the sub_grade column\n",
    "np.unique(loan_data_strings[:,3]).shape[0]+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b7f3c054",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A1': 1,\n",
       " 'A2': 2,\n",
       " 'A3': 3,\n",
       " 'A4': 4,\n",
       " 'A5': 5,\n",
       " 'B1': 6,\n",
       " 'B2': 7,\n",
       " 'B3': 8,\n",
       " 'B4': 9,\n",
       " 'B5': 10,\n",
       " 'C1': 11,\n",
       " 'C2': 12,\n",
       " 'C3': 13,\n",
       " 'C4': 14,\n",
       " 'C5': 15,\n",
       " 'D1': 16,\n",
       " 'D2': 17,\n",
       " 'D3': 18,\n",
       " 'D4': 19,\n",
       " 'D5': 20,\n",
       " 'E1': 21,\n",
       " 'E2': 22,\n",
       " 'E3': 23,\n",
       " 'E4': 24,\n",
       " 'E5': 25,\n",
       " 'F1': 26,\n",
       " 'F2': 27,\n",
       " 'F3': 28,\n",
       " 'F4': 29,\n",
       " 'F5': 30,\n",
       " 'G1': 31,\n",
       " 'G2': 32,\n",
       " 'G3': 33,\n",
       " 'G4': 34,\n",
       " 'G5': 35,\n",
       " 'H1': 36}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call  the dict sub grade variable\n",
    "dict_sub_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b274a8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use a loop to convert the elemnts of the sub grade to numeric elements\n",
    "for i in np.unique(loan_data_strings[:,3]):\n",
    "    loan_data_strings[:,3]=np.where(loan_data_strings[:,3]==i,\n",
    "                                     dict_sub_grade[i],\n",
    "                                     loan_data_strings[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "58dd2d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22',\n",
       "       '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36',\n",
       "       '4', '5', '6', '7', '8', '9'], dtype='<U69')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call np.unique of the subgrade column\n",
    "np.unique(loan_data_strings[:,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3554c7e",
   "metadata": {},
   "source": [
    "### Verification status "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "88e3be78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'verification_status'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call header_strings to view the content of the verification status\n",
    "header_strings[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6dcaef5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Verified', 'Source Verified', 'Verified', ..., 'Source Verified', 'Source Verified', ''],\n",
       "      dtype='<U69')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examine the data on the loan data strings\n",
    "loan_data_strings[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e700ae4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Not Verified', 'Source Verified', 'Verified'], dtype='<U69')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call the unique values of the verification strings\n",
    "np.unique(loan_data_strings[:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b351574",
   "metadata": {},
   "source": [
    "For the missing values, we would assume it is no verified since we assume the worse.\n",
    "\n",
    "for source verifed and verified, it represents loan applications which has investors backings. However, source verified has more  concrete backings. in this case we wppuld assume that the both are verified, and categorize them into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4cbebd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets use the where function to convert the values to numeric.0 for unverified and missing values, 1 for sourceverified&verifie\n",
    "loan_data_strings[:,4]=np.where((loan_data_strings[:,4]==\"\")|(loan_data_strings[:,4]==\"Not Verified\"),0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9750480",
   "metadata": {},
   "source": [
    "### URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "793e3a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226',\n",
       "       'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261',\n",
       "       'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726', ...,\n",
       "       'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990',\n",
       "       'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151',\n",
       "       'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249'], dtype='<U69')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the url column\n",
    "loan_data_strings[:,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1331a5d",
   "metadata": {},
   "source": [
    "we can see that the url address are mostly the same for each row, excpet for the loan id number at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1150fe79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chararray(['48010226', '57693261', '59432726', ..., '50415990', '46154151', '66055249'],\n",
       "          dtype='<U69')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets strip the url address for the url column\n",
    "np.chararray.strip(loan_data_strings[:,5],\"https://www.lendingclub.com/browse/loanDetail.action?loan_id=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2a221405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets overwrite the changes made \n",
    "loan_data_strings[:,5]=np.chararray.strip(loan_data_strings[:,5],\"https://www.lendingclub.com/browse/loanDetail.action?loan_id=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0817efdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'issue_d', 'loan_amnt', 'loan_status', 'funded_amnt', 'term', 'int_rate',\n",
       "       'installment', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state',\n",
       "       'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recall that we had a column id before spitting the dataset.\n",
    "#display header_full\n",
    "header_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9c5029d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48010226., 57693261., 59432726., ..., 50415990., 46154151., 66055249.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display the id column from the loan numeric\n",
    "loan_data_numeric[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c975fb7",
   "metadata": {},
   "source": [
    "We can see that the ids are synonymous with the values above from the url column, the url column is in strings while the id is in floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1b57249a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48010226, 57693261, 59432726, ..., 50415990, 46154151, 66055249])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets cast them both to integers\n",
    "loan_data_strings[:,5].astype(dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "409655aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48010226, 57693261, 59432726, ..., 50415990, 46154151, 66055249])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cast the url to integers\n",
    "loan_data_strings[:,5].astype(dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "64a27ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can use the array equal to check if they are both the same to be sure\n",
    "np.array_equal(loan_data_numeric[:,0].astype(dtype=int),loan_data_strings[:,5].astype(dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e50c5d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets delete the url column since it is the same with the id column from the numeric dataset.\n",
    "loan_data_strings=np.delete(loan_data_strings,5,axis=1)\n",
    "\n",
    "#also delete the url from the header_strings\n",
    "header_strings=np.delete(header_strings,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "09736df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CA', 'NY', 'PA', ..., 'CA', 'OH', 'IL'], dtype='<U69')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify that you have deleted the ur column\n",
    "loan_data_strings[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a7fe2c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'addr_state'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify that you have deleted the column name from the header strings\n",
    "header_strings[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ee033715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48010226., 57693261., 59432726., ..., 50415990., 46154151., 66055249.])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify the loan numeric\n",
    "loan_data_numeric[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "07a9adc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'id'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify the header numeric\n",
    "header_numeric[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b794f57",
   "metadata": {},
   "source": [
    "### State Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e0c90513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CA', 'NY', 'PA', ..., 'CA', 'OH', 'IL'], dtype='<U69')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call the state address from the loan data strings\n",
    "loan_data_strings[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "445ccf47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'addr_state'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call the header name for the last column\n",
    "header_strings[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f5709eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets rename it to state address\n",
    "header_strings[5]=\"state_address\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5d2642e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'HI', 'IL', 'IN',\n",
       "       'KS', 'KY', 'LA', 'MA', 'MD', 'ME', 'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH',\n",
       "       'NJ', 'NM', 'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VA',\n",
       "       'VT', 'WA', 'WI', 'WV', 'WY'], dtype='<U69')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the unique values from the state address\n",
    "np.unique(loan_data_strings[:,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a86f34d",
   "metadata": {},
   "source": [
    "we can see that these are the states in the united states. we also seem to have a missing value.  also, we would need to check if they are up to 50 states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "716d6408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the number of elemnts in the column\n",
    "np.unique(loan_data_strings[:,5]).size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac5ca6d",
   "metadata": {},
   "source": [
    "This means we have a state missing in the data, and the we must assume that the missing value represent the missing state in the column. The missing state is Iowa. we can say that this state was purposely left out as it must have been used as a baseline benchmark.\n",
    "\n",
    "When doing research or analysis on a variable with many categories, it is normal to pick one as a  benchmark and include dummy variables for the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "83459369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['', 'AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'HI', 'IL', 'IN',\n",
       "        'KS', 'KY', 'LA', 'MA', 'MD', 'ME', 'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH',\n",
       "        'NJ', 'NM', 'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VA',\n",
       "        'VT', 'WA', 'WI', 'WV', 'WY'], dtype='<U69'),\n",
       " array([ 500,   26,  119,   74,  220, 1336,  201,  143,   27,   27,  690,  321,   44,  389,  152,\n",
       "          84,   84,  116,  210,  222,   10,  267,  156,  160,   61,   28,  261,   16,   25,   58,\n",
       "         341,   57,  130,  777,  312,   83,  108,  320,   40,  107,   24,  143,  758,   74,  242,\n",
       "          17,  216,  148,   49,   27], dtype=int64))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets see the number of times they appear in the dataset\n",
    "np.unique(loan_data_strings[:,5],return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e2e86a",
   "metadata": {},
   "source": [
    "since we cant make sense of this, lets  return the  above in descending order using the argsort function. Thus will return the indices that will sort the arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ae2e4e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['CA', 'NY', 'TX', 'FL', '', 'IL', 'NJ', 'GA', 'PA', 'OH', 'MI', 'NC', 'VA', 'MD', 'AZ',\n",
       "        'WA', 'MA', 'CO', 'MO', 'MN', 'IN', 'WI', 'CT', 'TN', 'NV', 'AL', 'LA', 'OR', 'SC', 'KY',\n",
       "        'KS', 'OK', 'UT', 'AR', 'MS', 'NH', 'NM', 'WV', 'HI', 'RI', 'MT', 'DE', 'DC', 'WY', 'AK',\n",
       "        'NE', 'SD', 'VT', 'ND', 'ME'], dtype='<U69'),\n",
       " array([1336,  777,  758,  690,  500,  389,  341,  321,  320,  312,  267,  261,  242,  222,  220,\n",
       "         216,  210,  201,  160,  156,  152,  148,  143,  143,  130,  119,  116,  108,  107,   84,\n",
       "          84,   83,   74,   74,   61,   58,   57,   49,   44,   40,   28,   27,   27,   27,   26,\n",
       "          25,   24,   17,   16,   10], dtype=int64))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_name,state_count=np.unique(loan_data_strings[:,5],return_counts=True)\n",
    "state_count_sorted=np.argsort(-state_count)\n",
    "state_name[state_count_sorted],state_count[state_count_sorted]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2030f402",
   "metadata": {},
   "source": [
    "Unsurprisingly, we see thatbthe highest loan applications are from wealthy states and populous states in the us.\n",
    "\n",
    "We see that, we have 500 missing values which are larger than the 45 other states individually. Therefore, we have very little data for too many  states to examine each one individually.\n",
    "\n",
    "If we assign a uunique value to each state, this would allow outliers to have too many infkuence on the coefficients. To elaborate, the more categries a variable has, the fewer data will be available for earch one.\n",
    "\n",
    "To solve this problem, we need to group these states according to a certain characteristics, such as their geographical characteristics. \n",
    "\n",
    "Also, we would assign missing values with 0, to avoid creating a bias as well as causing outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "12bbe826",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets take care of the missing data\n",
    "loan_data_strings[:,5]=np.where(loan_data_strings[:,5]==\"\",\n",
    "                               0,\n",
    "                               loan_data_strings[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "38a9ffb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a state variable and store the names of the state in them\n",
    "states_west = np.array([\"WA\", \"OR\", \"CA\", \"NV\", \"ID\", \"MT\", \"WY\", \"UT\", \"CO\", \"AZ\", \"NM\", \"AK\", \"HI\"])\n",
    "states_south = np.array([\"TX\", \"OK\", \"AR\", \"LA\", \"MS\", \"AL\", \"TN\", \"KY\", \"FL\", \"GA\", \"SC\", \"NC\", \"VA\", \"WV\", \"MD\", \"DE\", \"DC\"])\n",
    "states_midwest = np.array([\"ND\", \"SD\", \"NE\", \"KS\", \"MN\", \"IA\", \"MO\", \"WI\", \"IL\", \"IN\", \"MI\", \"OH\"])\n",
    "states_east = np.array([\"ME\", \"NH\", \"VT\", \"MA\", \"RI\", \"CT\", \"NJ\", \"NY\", \"PA\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0c41498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use a where function to substitute for the regions and convert them to a numeric value\n",
    "loan_data_strings[:,5]=np.where(np.isin(loan_data_strings[:,5],states_west),1,loan_data_strings[:,5])\n",
    "loan_data_strings[:,5]=np.where(np.isin(loan_data_strings[:,5],states_south),2,loan_data_strings[:,5])\n",
    "loan_data_strings[:,5]=np.where(np.isin(loan_data_strings[:,5],states_midwest),3,loan_data_strings[:,5])\n",
    "loan_data_strings[:,5]=np.where(np.isin(loan_data_strings[:,5],states_east),4,loan_data_strings[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6a508e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '2', '3', '4'], dtype='<U69')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call the unique function on the the column\n",
    "np.unique(loan_data_strings[:,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e83b82",
   "metadata": {},
   "source": [
    "###   Converting to Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "075cc5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['5', '1', '36', '13', '1', '1'],\n",
       "       ['0', '1', '36', '5', '1', '4'],\n",
       "       ['9', '1', '36', '10', '1', '4'],\n",
       "       ...,\n",
       "       ['6', '1', '36', '5', '1', '1'],\n",
       "       ['4', '1', '36', '17', '1', '3'],\n",
       "       ['12', '1', '36', '4', '0', '3']], dtype='<U69')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display the strings dataset\n",
    "loan_data_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b1661a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  1, 36, 13,  1,  1],\n",
       "       [ 0,  1, 36,  5,  1,  4],\n",
       "       [ 9,  1, 36, 10,  1,  4],\n",
       "       ...,\n",
       "       [ 6,  1, 36,  5,  1,  1],\n",
       "       [ 4,  1, 36, 17,  1,  3],\n",
       "       [12,  1, 36,  4,  0,  3]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert the dataset from texts to strings\n",
    "loan_data_strings.astype(dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0a65756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets overwrite the entire dataset to contain integer values\n",
    "loan_data_strings=loan_data_strings.astype(dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a666d422",
   "metadata": {},
   "source": [
    "# Manipulating Numeric Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1e392d59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48010226., 57693261., 59432726., ..., 50415990., 46154151., 66055249.])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call the numeric data\n",
    "loan_data_numeric[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "de1c32e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for missing values in the dataset\n",
    "np.isnan(np.isin(loan_data_numeric[:,0],temporary_fill)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a49ec17",
   "metadata": {},
   "source": [
    "### Substitute Filler Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cb61be06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the first column in the header numeric\n",
    "#header_numer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d66d31dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#examine the id column on the loan data numeric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95b871a",
   "metadata": {},
   "source": [
    "since we filled our dataset with temporary fill, lets check to see if temporary fill is this column.\n",
    "usually, the id column are usually non nullable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8b7d8669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68616520.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call temporary_fill\n",
    "temporary_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b8142986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to  see if the temporary fill is in the id column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "034d1c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets get tthe sum to be sure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4154e3cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call header numeric\n",
    "header_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bec1e6d",
   "metadata": {},
   "source": [
    "For the loan_amt, int_rate, installment and total_payment, we will fill them with the maximum of the values in the columns while the funded amount will be filled with the minimum values of the column\n",
    "\n",
    "\n",
    "In loan applications, the following terms mean:\n",
    "\n",
    "- loan_amnt: The amount of money that the borrower is requesting to borrow.\n",
    "- funded_amnt: The amount of money that the borrower was actually approved for and received.\n",
    "- int_rate: The interest rate that the borrower will be charged on their loan.\n",
    "- installment: The monthly payment that the borrower will make on their loan.\n",
    "- total_pymnt: The total amount of money that the borrower will repay on their loan, including principal and interest.\n",
    "\n",
    "When preprocessing data for a credit risk model, it is common to fill in missing values in the following way:\n",
    "\n",
    "- For loan_amnt, int_rate, installment, and total_pymnt, fill in missing values with the maximum of the values in the columns. This is because a higher value for any of these variables indicates a higher risk of default.\n",
    "- For funded_amnt, fill in missing values with the minimum of the values in the columns. This is because a lower funded_amnt indicates that the borrower was approved for a smaller loan amount, which suggests that they are less of a risk to the lender.\n",
    "\n",
    "This approach to filling in missing values is justified by the fact that we are trying to build a credit risk model to predict the probability of default. By filling in missing values with the maximum or minimum values, we are erring on the side of caution and assuming that the borrower is a higher risk than they actually are. This will help to ensure that our model does not underestimate the risk of default and that we are able to accurately identify borrowers who are at risk of defaulting on their loans."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20ba570",
   "metadata": {},
   "source": [
    "### Temporary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9c7d589e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  373332.  ,         nan,     1000.  ,         nan,     1000.  ,         nan,        6.  ,\n",
       "              31.42,         nan,         nan,         nan,         nan,         nan,        0.  ],\n",
       "       [54015809.19,         nan,    15273.46,         nan,    15311.04,         nan,       16.62,\n",
       "             440.92,         nan,         nan,         nan,         nan,         nan,     3143.85],\n",
       "       [68616519.  ,         nan,    35000.  ,         nan,    35000.  ,         nan,       28.99,\n",
       "            1372.97,         nan,         nan,         nan,         nan,         nan,    41913.62]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call temporary stats\n",
    "temporary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bda6662b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  373332.  ,     1000.  ,     1000.  ,        6.  ,       31.42,        0.  ],\n",
       "       [54015809.19,    15273.46,    15311.04,       16.62,      440.92,     3143.85],\n",
       "       [68616519.  ,    35000.  ,    35000.  ,       28.99,     1372.97,    41913.62]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets remove the  columns with nan or in this  case text values\n",
    "temporary_stats[:,column_numeric]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c2c7be",
   "metadata": {},
   "source": [
    "### Funded Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9f5893c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'funded_amnt'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call the funded amount in the header numeric\n",
    "header_numeric[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ca1b2eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35000., 30000., 15000., ..., 10000., 10000., 10000.])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examine the dataset in the loan numeric\n",
    "loan_data_numeric[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "540947c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets substitute the temporary fill in the funded amount wiht the nanmin in the column\n",
    "loan_data_numeric[:,2]=np.where(loan_data_numeric[:,2]==temporary_fill,\n",
    "                               temporary_stats[0,column_numeric[2]],\n",
    "                               loan_data_numeric[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c0274b",
   "metadata": {},
   "source": [
    "### Loaned Amount, Interest Rate, Total Payment and Installment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0cf32845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call header numeric\n",
    "header_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "064ed695",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets substitute the temporary_fill(missing values) with the maximum in each column. lets use a for loop\n",
    "for i in [1,3,4,5]:\n",
    "    loan_data_numeric[:,i]=np.where(loan_data_numeric[:,i]==temporary_fill,\n",
    "                                   temporary_stats[2,column_numeric[i]],\n",
    "                                loan_data_numeric[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6e0d7e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    35000.  ,       13.33,     1184.86,     9452.96],\n",
       "       [57693261.  ,    30000.  ,    30000.  ,       28.99,      938.57,     4679.7 ],\n",
       "       [59432726.  ,    15000.  ,    15000.  ,       28.99,      494.86,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,    10000.  ,       28.99,     1372.97,     2185.64],\n",
       "       [46154151.  ,    35000.  ,    10000.  ,       16.55,      354.3 ,     3199.4 ],\n",
       "       [66055249.  ,    10000.  ,    10000.  ,       28.99,      309.97,      301.9 ]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call the loan_numeric data\n",
    "loan_data_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9329fa1",
   "metadata": {},
   "source": [
    "### Data Currency Change- The Exchange Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7de3a218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Open', 'High', 'Low', 'Close', 'Volume'],\n",
       "       ['1.2098628282546997', '1.2098628282546997', '1.11055588722229', '1.1287955045700073', '0'],\n",
       "       ['1.1287955045700073', '1.1484194993972778', '1.117680549621582', '1.1205360889434814',\n",
       "        '0'],\n",
       "       ['1.119795799255371', '1.1240400075912476', '1.0460032224655151', '1.0830246210098267',\n",
       "        '0'],\n",
       "       ['1.0741022825241089', '1.1247594356536865', '1.0521597862243652', '1.1114321947097778',\n",
       "        '0'],\n",
       "       ['1.1215037107467651', '1.145304799079895', '1.0821995735168457', '1.0960345268249512',\n",
       "        '0'],\n",
       "       ['1.095902442932129', '1.1428401470184326', '1.0888904333114624', '1.122296690940857', '0'],\n",
       "       ['1.1134989261627197', '1.1219995021820068', '1.081270456314087', '1.0939244031906128',\n",
       "        '0'],\n",
       "       ['1.0969001054763794', '1.1705996990203857', '1.0850305557250977', '1.1340054273605347',\n",
       "        '0'],\n",
       "       ['1.1225990056991577', '1.1460003852844238', '1.1089695692062378', '1.1255937814712524',\n",
       "        '0'],\n",
       "       ['1.1171561479568481', '1.1494200229644775', '1.0910003185272217', '1.100897192955017',\n",
       "        '0'],\n",
       "       ['1.1024993658065796', '1.1060001850128174', '1.056400179862976', '1.0583018064498901',\n",
       "        '0'],\n",
       "       ['1.0572947263717651', '1.107000470161438', '1.0541995763778687', '1.093398094177246', '0']],\n",
       "      dtype='<U18')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the eur_usd using the genfromtxt. set the dype to strings to see the column names \n",
    "eur_usd=np.genfromtxt(\"C:\\\\Users\\\\USER\\\\Downloads\\\\EUR-USD.csv\",\n",
    "                     delimiter=',',\n",
    "                     autostrip=True,\n",
    "                     dtype=str)\n",
    "eur_usd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5ff20c",
   "metadata": {},
   "source": [
    "The eur_usd contains the open, high, low, close and volume that was traded. The eur_usd represents the average monthly prices for dollar to eur for the year 2015. The close however, is the adjusted closing prices. We are  only interested in the closing prices however. so we have to import just that and skip the headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "90c26c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.13, 1.12, 1.08, 1.11, 1.1 , 1.12, 1.09, 1.13, 1.13, 1.1 , 1.06, 1.09])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets reimport the dataset, using the above conditions\n",
    "eur_usd=np.genfromtxt(\"C:\\\\Users\\\\USER\\\\Downloads\\\\EUR-USD.csv\",\n",
    "                     delimiter=',',\n",
    "                     autostrip=True,\n",
    "                     skip_header=1,\n",
    "                     usecols=[3])\n",
    "eur_usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6508148b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  0,  9, ...,  6,  4, 12])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the issue date column from the loan data strings\n",
    "loan_data_strings[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365509e9",
   "metadata": {},
   "source": [
    "This contains all respective dates the loan was  issued. what we would do here, is tht we would  set the monthly numbers in loan_data_strings  to a variable exchange rates then replaces those months in exchange rates, with the close values in eur_usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c15e683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set exchange rates to issue date  \n",
    "exchange_rates=loan_data_strings[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "95c8807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use a for loop to to iterate over all the months excluding month 0 which represents the missing values and store the monthly exchange rates\n",
    "#for each month there\n",
    "for i in range(1,13):\n",
    "    exchange_rates=np.where(exchange_rates==i,\n",
    "                          eur_usd[i-1],\n",
    "                           exchange_rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8778b8",
   "metadata": {},
   "source": [
    "now  we still have 0 in the exchnage rates which is the missing values or unaccounted issue date, lets store the mean of the yearly rates for the adjusted close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c90c9567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the np.where to store the mean for where it is 0.\n",
    "exchange_rates=np.where(exchange_rates==0,\n",
    "                       np.mean(eur_usd),\n",
    "                       exchange_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "47f9166a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exchange_rates_shape (10000,)\n",
      "loan data Numeric shape: (10000, 6)\n"
     ]
    }
   ],
   "source": [
    "#lets store exchange rates to the dataset. first of all lets check to see that their shaoes are compatible\n",
    "print('exchange_rates_shape',  exchange_rates.shape)\n",
    "print(\"loan data Numeric shape:\", loan_data_numeric.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b889124c",
   "metadata": {},
   "source": [
    "Their shapes are incompatible, as exchange rates is 1d while loan data numeric is 2d, however, they have the same number of rows. so we have to reshape exchange rates so that it can become 2d and also be compatible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f52b635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape the exchange rates to a 2d object\n",
    "exchange_rates=np.reshape(exchange_rates,(10000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a8206af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets store the exchange rates in the loan data numeric dataset\n",
    "loan_data_numeric=np.hstack((loan_data_numeric,exchange_rates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8bfd1676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets also ensure  that the exchange rate column is added to the header numeric.\n",
    "header_numeric=np.concatenate((header_numeric,np.array([\"exchange_rates\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f84684",
   "metadata": {},
   "source": [
    "### From USD to Eur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f6519f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt',\n",
       "       'exchange_rates'], dtype='<U19')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets call the header numeric\n",
    "header_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8f0690",
   "metadata": {},
   "source": [
    "we can see that from the header, loan  amount, funded amount, installment, total payment. are all in dollars therefore we have to chnage them to their Euro equivaluent for eachmonth of the application for the year 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6400d10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a variable and store the columns we are interested in\n",
    "column_dollars=[1,2,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9f9465b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35000.  , 35000.  ,  1184.86,  9452.96],\n",
       "       [30000.  , 30000.  ,   938.57,  4679.7 ],\n",
       "       [15000.  , 15000.  ,   494.86,  1969.83],\n",
       "       ...,\n",
       "       [10000.  , 10000.  ,  1372.97,  2185.64],\n",
       "       [35000.  , 10000.  ,   354.3 ,  3199.4 ],\n",
       "       [10000.  , 10000.  ,   309.97,   301.9 ]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call loan_numeric, and pass the column index to it to be sure it actually gets you the columns you are interested in for conver\n",
    "loan_data_numeric[:,column_dollars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a698080e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1 , 1.11, 1.13, ..., 1.12, 1.11, 1.09])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the exchange rates column from the loan data numeric\n",
    "loan_data_numeric[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f0536b",
   "metadata": {},
   "source": [
    "To convert values from dollars to euros using exchange rates, you should divide the dollar values by the exchange rate. This is because the exchange rate tells you how many euros you get for one dollar. So, to convert from dollars to euros, you need to divide the dollar value by the exchange rate.\n",
    "\n",
    "- Exchange Rate: The exchange rate tells you how many euros you get for one dollar. For example, if the exchange rate is 0.85, it means you get 0.85 euros for each dollar.\n",
    "\n",
    "- Conversion Formula: To convert a dollar amount to euros, you need to divide the dollar amount by the exchange rate. This is because you're essentially asking, \"How many times does the exchange rate fit into the dollar amount?\"\n",
    "\n",
    "Euros = Dollars / Exchange Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7b9b7a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use a for loop to store the rates of the for each column. essentially we are adding new columns for every division.\n",
    "for i in column_dollars:\n",
    "    loan_data_numeric=np.hstack((loan_data_numeric,np.reshape(loan_data_numeric[:,i]/loan_data_numeric[:,-1],(10000,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "00c1e79f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call loan numeric and get the shape as well\n",
    "loan_data_numeric.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004354c5",
   "metadata": {},
   "source": [
    "We see that the new columns has been stored in the dataset, therefore, we have to attach the column names to the header numeric.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e34941",
   "metadata": {},
   "source": [
    "### Expanding the Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b938f1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the column names in header numeric for where the conversion has taken place and attach eur to the name.\n",
    "\n",
    "header_additional=[column_name+\"_USD\" for column_name in header_numeric[column_dollars]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d964a1a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt',\n",
       "       'exchange_rates', 'loan_amnt_USD', 'funded_amnt_USD', 'installment_USD', 'total_pymnt_USD'],\n",
       "      dtype='<U19')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets get concatenate the column names to the header numeric\n",
    "header_numeric=np.concatenate((header_numeric,header_additional))\n",
    "header_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6febde94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt_EUR', 'funded_amnt_EUR', 'int_rate', 'installment_EUR', 'total_pymnt_EUR',\n",
       "       'exchange_rates', 'loan_amnt_USD', 'funded_amnt_USD', 'installment_USD', 'total_pymnt_USD'],\n",
       "      dtype='<U19')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets make our headers more distinct. store the other columns with dollar names\n",
    "header_numeric[column_dollars]=[column_name + \"_EUR\" for column_name in header_numeric[column_dollars]]\n",
    "header_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dae5aee",
   "metadata": {},
   "source": [
    "Now it looks better, however, it can be imporved  Lets store the usd and eur side by side. The best way to achieve this, is through a list, as there is no elegant way to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "30b15c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the columns index order that will be side by side to each other.  the exchange rates should be last\n",
    "column_index_sort_order=[0,1,7,2,8,3,4,9,5,10,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6ab478be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt_EUR', 'loan_amnt_USD', 'funded_amnt_EUR', 'funded_amnt_USD', 'int_rate',\n",
       "       'installment_EUR', 'installment_USD', 'total_pymnt_EUR', 'total_pymnt_USD',\n",
       "       'exchange_rates'], dtype='<U19')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pass the column index order as an index to header numeric\n",
    "header_numeric[column_index_sort_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c7c936af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets overwrite it and make it permanent\n",
    "header_full=header_numeric[column_index_sort_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "89b9b4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    31933.3 , ...,     9452.96,        8.74,        1.1 ],\n",
       "       [57693261.  ,    30000.  ,    27132.46, ...,     4679.7 ,        5.51,        1.11],\n",
       "       [59432726.  ,    15000.  ,    13326.3 , ...,     1969.83,        4.48,        1.13],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,     8910.3 , ...,     2185.64,        1.79,        1.12],\n",
       "       [46154151.  ,    35000.  ,    31490.9 , ...,     3199.4 ,        2.87,        1.11],\n",
       "       [66055249.  ,    10000.  ,     9145.8 , ...,      301.9 ,        1.06,        1.09]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets repeat the same thing for loan_data. pass the column index order to loan data numeric\n",
    "loan_data_numeric[:,column_index_sort_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f65a8436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#overwite the loan data numeric use the column index order as index\n",
    "loan_data_numeric=loan_data_numeric[:,column_index_sort_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "28ebaa44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    31933.3 , ...,     9452.96,        8.74,        1.1 ],\n",
       "       [57693261.  ,    30000.  ,    27132.46, ...,     4679.7 ,        5.51,        1.11],\n",
       "       [59432726.  ,    15000.  ,    13326.3 , ...,     1969.83,        4.48,        1.13],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,     8910.3 , ...,     2185.64,        1.79,        1.12],\n",
       "       [46154151.  ,    35000.  ,    31490.9 , ...,     3199.4 ,        2.87,        1.11],\n",
       "       [66055249.  ,    10000.  ,     9145.8 , ...,      301.9 ,        1.06,        1.09]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eaa08b",
   "metadata": {},
   "source": [
    "### Interest Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "71105102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt_EUR', 'funded_amnt_EUR', 'int_rate', 'installment_EUR', 'total_pymnt_EUR',\n",
       "       'exchange_rates', 'loan_amnt_USD', 'funded_amnt_USD', 'installment_USD', 'total_pymnt_USD'],\n",
       "      dtype='<U19')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call the interest rate column on the header numeric\n",
    "header_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "54cd6ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.33, 28.99, 28.99, ..., 28.99, 16.55, 28.99])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data_numeric[:,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c43a5f",
   "metadata": {},
   "source": [
    "We see that the interest rates are percentages for the rates charged to loan applicants. however this interest rates  are between 1 -100, convention dictates the interest rates are between 0 and 1  for ease of analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4d2f04e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13, 0.29, 0.29, ..., 0.29, 0.17, 0.29])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert it to decimals between 0 and 1\n",
    "loan_data_numeric[:,5]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "94b4acda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the interest rates column to be sure\n",
    "loan_data_numeric[:,5]=loan_data_numeric[:,5]/100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecd567d",
   "metadata": {},
   "source": [
    "### Merging and Completing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770b123c",
   "metadata": {},
   "source": [
    "before we merge the both datasets, we have to ensure that they have compatible  shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "969baff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 6)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the shape of the string dataset\n",
    "loan_data_strings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "36e903f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for the shape of the numeric dataset\n",
    "loan_data_numeric.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d87dcd",
   "metadata": {},
   "source": [
    "both datasets, contains the same number of rows, which means that we can stack them side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "640fb97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    31933.3 , ...,       13.  ,        1.  ,        1.  ],\n",
       "       [57693261.  ,    30000.  ,    27132.46, ...,        5.  ,        1.  ,        4.  ],\n",
       "       [59432726.  ,    15000.  ,    13326.3 , ...,       10.  ,        1.  ,        4.  ],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,     8910.3 , ...,        5.  ,        1.  ,        1.  ],\n",
       "       [46154151.  ,    35000.  ,    31490.9 , ...,       17.  ,        1.  ,        3.  ],\n",
       "       [66055249.  ,    10000.  ,     9145.8 , ...,        4.  ,        0.  ,        3.  ]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can merge them together, using the hstack or by concatenating the dataste\n",
    "np.hstack((loan_data_numeric,loan_data_strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6e107429",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the stacked array in the loan_data variable\n",
    "loan_data=np.hstack((loan_data_numeric,loan_data_strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3ee9ada1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    31933.3 , ...,       13.  ,        1.  ,        1.  ],\n",
       "       [57693261.  ,    30000.  ,    27132.46, ...,        5.  ,        1.  ,        4.  ],\n",
       "       [59432726.  ,    15000.  ,    13326.3 , ...,       10.  ,        1.  ,        4.  ],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,     8910.3 , ...,        5.  ,        1.  ,        1.  ],\n",
       "       [46154151.  ,    35000.  ,    31490.9 , ...,       17.  ,        1.  ,        3.  ],\n",
       "       [66055249.  ,    10000.  ,     9145.8 , ...,        4.  ,        0.  ,        3.  ]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9e7224d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets check for missing values once more, to be sure we ave treated them accordingly.\n",
    "np.isnan(loan_data).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "914b16bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt_EUR', 'funded_amnt_EUR', 'int_rate', 'installment_EUR', 'total_pymnt_EUR',\n",
       "       'exchange_rates', 'loan_amnt_USD', 'funded_amnt_USD', 'installment_USD', 'total_pymnt_USD',\n",
       "       'issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status',\n",
       "       'state_address'], dtype='<U19')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets merge the headers toggether\n",
    "np.concatenate((header_numeric,header_strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9a2cabc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the merged headers and store them in a variable.\n",
    "header_full=np.concatenate((header_numeric,header_strings))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad153ea",
   "metadata": {},
   "source": [
    "### Sorting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ac970bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  373332.,   575239.,   707689., ..., 68614880., 68615915., 68616519.])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets sort thhe dataset, based on the first column which is id\n",
    "np.sort(loan_data[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "622c350f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  373332.  ,     9950.  ,     9038.08, ...,       21.  ,        0.  ,        1.  ],\n",
       "       [  575239.  ,    12000.  ,    10900.2 , ...,       36.  ,        1.  ,        2.  ],\n",
       "       [  707689.  ,    10000.  ,     8924.3 , ...,       13.  ,        1.  ,        0.  ],\n",
       "       ...,\n",
       "       [68614880.  ,     5600.  ,     5121.65, ...,        8.  ,        1.  ,        1.  ],\n",
       "       [68615915.  ,     4000.  ,     3658.32, ...,       10.  ,        1.  ,        2.  ],\n",
       "       [68616519.  ,    21600.  ,    19754.93, ...,        3.  ,        0.  ,        2.  ]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets use the argsort function as an index of the loan_data\n",
    "loan_data[np.argsort(loan_data[:,0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "387bdc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets store the values in the loan_data\n",
    "loan_data=loan_data[np.argsort(loan_data[:,0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "cce9c830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 9997, 9998, 9999], dtype=int64)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to be sure it has been sorted, we can use the argort the indices that will sort the array\n",
    "np.argsort(loan_data[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55ac0aa",
   "metadata": {},
   "source": [
    "### Storing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ba461353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['id', 'loan_amnt_EUR', 'funded_amnt_EUR', ..., 'sub_grade', 'verification_status',\n",
       "        'state_address'],\n",
       "       ['373332.0', '9950.0', '9038.082814338286', ..., '21.0', '0.0', '1.0'],\n",
       "       ['575239.0', '12000.0', '10900.20037910145', ..., '36.0', '1.0', '2.0'],\n",
       "       ...,\n",
       "       ['68614880.0', '5600.0', '5121.647851612413', ..., '8.0', '1.0', '1.0'],\n",
       "       ['68615915.0', '4000.0', '3658.319894008867', ..., '10.0', '1.0', '2.0'],\n",
       "       ['68616519.0', '21600.0', '19754.927427647883', ..., '3.0', '0.0', '2.0']], dtype='<U32')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge the header with the rest of the dataset\n",
    "np.vstack((header_full,loan_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9128f6b7",
   "metadata": {},
   "source": [
    "We see that the dataset is now in the strings format, this is because the stacking function requires a unified data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a2920191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets store the above in a variable\n",
    "loan_data=np.vstack((header_full,loan_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7200fd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets save the file to an external eenvironment\n",
    "np.savetxt(\"loan-data-Preprocessed.csv\",loan_data,fmt='%s',delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294c5c4e",
   "metadata": {},
   "source": [
    "Now we have cleaned, preprocessed and Transformed the Dataset, now the data science team can use this dataset to build a Credit Risk Model that predicts the probability of default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab69955",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
